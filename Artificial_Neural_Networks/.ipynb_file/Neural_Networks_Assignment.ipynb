{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f36eeea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pradnyan Thakare\\AppData\\Local\\Temp\\ipykernel_20916\\2746718312.py:11: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from sklearn.metrics import classification_report\n",
    "import keras_tuner as kt\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Adadelta, RMSprop\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2044d8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>C</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>T</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  \\\n",
       "0          T     2     8      3       5      1     8    13      0      6   \n",
       "1          I     5    12      3       7      2    10     5      5      4   \n",
       "2          D     4    11      6       8      6    10     6      2      6   \n",
       "3          N     7    11      6       6      3     5     9      4      6   \n",
       "4          G     2     1      3       1      1     8     6      6      6   \n",
       "...      ...   ...   ...    ...     ...    ...   ...   ...    ...    ...   \n",
       "19995      D     2     2      3       3      2     7     7      7      6   \n",
       "19996      C     7    10      8       8      4     4     8      6      9   \n",
       "19997      T     6     9      6       7      5     6    11      3      7   \n",
       "19998      S     2     3      4       2      1     8     7      2      6   \n",
       "19999      A     4     9      6       6      2     9     5      3      1   \n",
       "\n",
       "       xybar  x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "0          6      10       8      0       8      0       8  \n",
       "1         13       3       9      2       8      4      10  \n",
       "2         10       3       7      3       7      3       9  \n",
       "3          4       4      10      6      10      2       8  \n",
       "4          6       5       9      1       7      5      10  \n",
       "...      ...     ...     ...    ...     ...    ...     ...  \n",
       "19995      6       6       4      2       8      3       7  \n",
       "19996     12       9      13      2       9      3       7  \n",
       "19997     11       9       5      2      12      2       4  \n",
       "19998     10       6       8      1       9      5       8  \n",
       "19999      8       1       8      2       7      2       8  \n",
       "\n",
       "[20000 rows x 17 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uploading Dataset\n",
    "df = pd.read_csv('Alphabets_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a808faf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   letter  20000 non-null  object\n",
      " 1   xbox    20000 non-null  int64 \n",
      " 2   ybox    20000 non-null  int64 \n",
      " 3   width   20000 non-null  int64 \n",
      " 4   height  20000 non-null  int64 \n",
      " 5   onpix   20000 non-null  int64 \n",
      " 6   xbar    20000 non-null  int64 \n",
      " 7   ybar    20000 non-null  int64 \n",
      " 8   x2bar   20000 non-null  int64 \n",
      " 9   y2bar   20000 non-null  int64 \n",
      " 10  xybar   20000 non-null  int64 \n",
      " 11  x2ybar  20000 non-null  int64 \n",
      " 12  xy2bar  20000 non-null  int64 \n",
      " 13  xedge   20000 non-null  int64 \n",
      " 14  xedgey  20000 non-null  int64 \n",
      " 15  yedge   20000 non-null  int64 \n",
      " 16  yedgex  20000 non-null  int64 \n",
      "dtypes: int64(16), object(1)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Checking dataset info.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8783947d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "letter    0\n",
       "xbox      0\n",
       "ybox      0\n",
       "width     0\n",
       "height    0\n",
       "onpix     0\n",
       "xbar      0\n",
       "ybar      0\n",
       "x2bar     0\n",
       "y2bar     0\n",
       "xybar     0\n",
       "x2ybar    0\n",
       "xy2bar    0\n",
       "xedge     0\n",
       "xedgey    0\n",
       "yedge     0\n",
       "yedgex    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values in dataframe\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7141dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No missing values are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be737acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining features and labels\n",
    "X = df.iloc[:, 1:]\n",
    "Y = df['letter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "317ab79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.057698</td>\n",
       "      <td>0.291877</td>\n",
       "      <td>-1.053277</td>\n",
       "      <td>-0.164704</td>\n",
       "      <td>-1.144013</td>\n",
       "      <td>0.544130</td>\n",
       "      <td>2.365097</td>\n",
       "      <td>-1.714360</td>\n",
       "      <td>0.344994</td>\n",
       "      <td>-0.917071</td>\n",
       "      <td>1.347774</td>\n",
       "      <td>0.034125</td>\n",
       "      <td>-1.305948</td>\n",
       "      <td>-0.219082</td>\n",
       "      <td>-1.438153</td>\n",
       "      <td>0.122911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.510385</td>\n",
       "      <td>1.502358</td>\n",
       "      <td>-1.053277</td>\n",
       "      <td>0.719730</td>\n",
       "      <td>-0.687476</td>\n",
       "      <td>1.531305</td>\n",
       "      <td>-1.075326</td>\n",
       "      <td>0.137561</td>\n",
       "      <td>-0.495072</td>\n",
       "      <td>1.895968</td>\n",
       "      <td>-1.312807</td>\n",
       "      <td>0.514764</td>\n",
       "      <td>-0.448492</td>\n",
       "      <td>-0.219082</td>\n",
       "      <td>0.120081</td>\n",
       "      <td>1.359441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.012309</td>\n",
       "      <td>1.199738</td>\n",
       "      <td>0.435910</td>\n",
       "      <td>1.161947</td>\n",
       "      <td>1.138672</td>\n",
       "      <td>1.531305</td>\n",
       "      <td>-0.645273</td>\n",
       "      <td>-0.973591</td>\n",
       "      <td>0.344994</td>\n",
       "      <td>0.690380</td>\n",
       "      <td>-1.312807</td>\n",
       "      <td>-0.446513</td>\n",
       "      <td>-0.019764</td>\n",
       "      <td>-0.865626</td>\n",
       "      <td>-0.269477</td>\n",
       "      <td>0.741176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.555774</td>\n",
       "      <td>1.199738</td>\n",
       "      <td>0.435910</td>\n",
       "      <td>0.277513</td>\n",
       "      <td>-0.230939</td>\n",
       "      <td>-0.936631</td>\n",
       "      <td>0.644886</td>\n",
       "      <td>-0.232823</td>\n",
       "      <td>0.344994</td>\n",
       "      <td>-1.720796</td>\n",
       "      <td>-0.932724</td>\n",
       "      <td>0.995402</td>\n",
       "      <td>1.266419</td>\n",
       "      <td>1.074008</td>\n",
       "      <td>-0.659036</td>\n",
       "      <td>0.122911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.057698</td>\n",
       "      <td>-1.826464</td>\n",
       "      <td>-1.053277</td>\n",
       "      <td>-1.933571</td>\n",
       "      <td>-1.144013</td>\n",
       "      <td>0.544130</td>\n",
       "      <td>-0.645273</td>\n",
       "      <td>0.507945</td>\n",
       "      <td>0.344994</td>\n",
       "      <td>-0.917071</td>\n",
       "      <td>-0.552641</td>\n",
       "      <td>0.514764</td>\n",
       "      <td>-0.877220</td>\n",
       "      <td>-0.865626</td>\n",
       "      <td>0.509640</td>\n",
       "      <td>1.359441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>-1.057698</td>\n",
       "      <td>-1.523844</td>\n",
       "      <td>-1.053277</td>\n",
       "      <td>-1.049137</td>\n",
       "      <td>-0.687476</td>\n",
       "      <td>0.050543</td>\n",
       "      <td>-0.215220</td>\n",
       "      <td>0.878329</td>\n",
       "      <td>0.344994</td>\n",
       "      <td>-0.917071</td>\n",
       "      <td>-0.172558</td>\n",
       "      <td>-1.888428</td>\n",
       "      <td>-0.448492</td>\n",
       "      <td>-0.219082</td>\n",
       "      <td>-0.269477</td>\n",
       "      <td>-0.495354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>1.555774</td>\n",
       "      <td>0.897117</td>\n",
       "      <td>1.428701</td>\n",
       "      <td>1.161947</td>\n",
       "      <td>0.225598</td>\n",
       "      <td>-1.430218</td>\n",
       "      <td>0.214833</td>\n",
       "      <td>0.507945</td>\n",
       "      <td>1.605094</td>\n",
       "      <td>1.494105</td>\n",
       "      <td>0.967691</td>\n",
       "      <td>2.437316</td>\n",
       "      <td>-0.448492</td>\n",
       "      <td>0.427463</td>\n",
       "      <td>-0.269477</td>\n",
       "      <td>-0.495354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>1.033079</td>\n",
       "      <td>0.594497</td>\n",
       "      <td>0.435910</td>\n",
       "      <td>0.719730</td>\n",
       "      <td>0.682135</td>\n",
       "      <td>-0.443044</td>\n",
       "      <td>1.504991</td>\n",
       "      <td>-0.603207</td>\n",
       "      <td>0.765028</td>\n",
       "      <td>1.092242</td>\n",
       "      <td>0.967691</td>\n",
       "      <td>-1.407789</td>\n",
       "      <td>-0.448492</td>\n",
       "      <td>2.367097</td>\n",
       "      <td>-0.659036</td>\n",
       "      <td>-2.350149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>-1.057698</td>\n",
       "      <td>-1.221224</td>\n",
       "      <td>-0.556881</td>\n",
       "      <td>-1.491354</td>\n",
       "      <td>-1.144013</td>\n",
       "      <td>0.544130</td>\n",
       "      <td>-0.215220</td>\n",
       "      <td>-0.973591</td>\n",
       "      <td>0.344994</td>\n",
       "      <td>0.690380</td>\n",
       "      <td>-0.172558</td>\n",
       "      <td>0.034125</td>\n",
       "      <td>-0.877220</td>\n",
       "      <td>0.427463</td>\n",
       "      <td>0.509640</td>\n",
       "      <td>0.122911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>-0.012309</td>\n",
       "      <td>0.594497</td>\n",
       "      <td>0.435910</td>\n",
       "      <td>0.277513</td>\n",
       "      <td>-0.687476</td>\n",
       "      <td>1.037718</td>\n",
       "      <td>-1.075326</td>\n",
       "      <td>-0.603207</td>\n",
       "      <td>-1.755172</td>\n",
       "      <td>-0.113345</td>\n",
       "      <td>-2.072973</td>\n",
       "      <td>0.034125</td>\n",
       "      <td>-0.448492</td>\n",
       "      <td>-0.865626</td>\n",
       "      <td>-0.659036</td>\n",
       "      <td>0.122911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           xbox      ybox     width    height     onpix      xbar      ybar  \\\n",
       "0     -1.057698  0.291877 -1.053277 -0.164704 -1.144013  0.544130  2.365097   \n",
       "1      0.510385  1.502358 -1.053277  0.719730 -0.687476  1.531305 -1.075326   \n",
       "2     -0.012309  1.199738  0.435910  1.161947  1.138672  1.531305 -0.645273   \n",
       "3      1.555774  1.199738  0.435910  0.277513 -0.230939 -0.936631  0.644886   \n",
       "4     -1.057698 -1.826464 -1.053277 -1.933571 -1.144013  0.544130 -0.645273   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "19995 -1.057698 -1.523844 -1.053277 -1.049137 -0.687476  0.050543 -0.215220   \n",
       "19996  1.555774  0.897117  1.428701  1.161947  0.225598 -1.430218  0.214833   \n",
       "19997  1.033079  0.594497  0.435910  0.719730  0.682135 -0.443044  1.504991   \n",
       "19998 -1.057698 -1.221224 -0.556881 -1.491354 -1.144013  0.544130 -0.215220   \n",
       "19999 -0.012309  0.594497  0.435910  0.277513 -0.687476  1.037718 -1.075326   \n",
       "\n",
       "          x2bar     y2bar     xybar    x2ybar    xy2bar     xedge    xedgey  \\\n",
       "0     -1.714360  0.344994 -0.917071  1.347774  0.034125 -1.305948 -0.219082   \n",
       "1      0.137561 -0.495072  1.895968 -1.312807  0.514764 -0.448492 -0.219082   \n",
       "2     -0.973591  0.344994  0.690380 -1.312807 -0.446513 -0.019764 -0.865626   \n",
       "3     -0.232823  0.344994 -1.720796 -0.932724  0.995402  1.266419  1.074008   \n",
       "4      0.507945  0.344994 -0.917071 -0.552641  0.514764 -0.877220 -0.865626   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "19995  0.878329  0.344994 -0.917071 -0.172558 -1.888428 -0.448492 -0.219082   \n",
       "19996  0.507945  1.605094  1.494105  0.967691  2.437316 -0.448492  0.427463   \n",
       "19997 -0.603207  0.765028  1.092242  0.967691 -1.407789 -0.448492  2.367097   \n",
       "19998 -0.973591  0.344994  0.690380 -0.172558  0.034125 -0.877220  0.427463   \n",
       "19999 -0.603207 -1.755172 -0.113345 -2.072973  0.034125 -0.448492 -0.865626   \n",
       "\n",
       "          yedge    yedgex  \n",
       "0     -1.438153  0.122911  \n",
       "1      0.120081  1.359441  \n",
       "2     -0.269477  0.741176  \n",
       "3     -0.659036  0.122911  \n",
       "4      0.509640  1.359441  \n",
       "...         ...       ...  \n",
       "19995 -0.269477 -0.495354  \n",
       "19996 -0.269477 -0.495354  \n",
       "19997 -0.659036 -2.350149  \n",
       "19998  0.509640  0.122911  \n",
       "19999 -0.659036  0.122911  \n",
       "\n",
       "[20000 rows x 16 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying standardization on features\n",
    "sc = StandardScaler()\n",
    "x = sc.fit_transform(X)\n",
    "x = pd.DataFrame(x, columns=X.columns)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd0ea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding label column.\n",
    "y = pd.get_dummies(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1c00c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into training and testing parts\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1945deb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1676 - loss: 2.8967\n",
      "Epoch 2/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5600 - loss: 1.5030\n",
      "Epoch 3/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6607 - loss: 1.1391\n",
      "Epoch 4/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7033 - loss: 1.0002\n",
      "Epoch 5/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7284 - loss: 0.9156\n",
      "Epoch 6/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7461 - loss: 0.8563\n",
      "Epoch 7/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7652 - loss: 0.7833\n",
      "Epoch 8/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7664 - loss: 0.7734\n",
      "Epoch 9/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7856 - loss: 0.7176\n",
      "Epoch 10/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7880 - loss: 0.7017\n",
      "Epoch 11/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8016 - loss: 0.6625\n",
      "Epoch 12/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8105 - loss: 0.6457\n",
      "Epoch 13/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8072 - loss: 0.6529\n",
      "Epoch 14/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8147 - loss: 0.6247\n",
      "Epoch 15/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8243 - loss: 0.5855\n",
      "Epoch 16/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8269 - loss: 0.5852\n",
      "Epoch 17/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8326 - loss: 0.5594\n",
      "Epoch 18/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8357 - loss: 0.5538\n",
      "Epoch 19/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8388 - loss: 0.5304\n",
      "Epoch 20/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.5224\n",
      "Epoch 21/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8444 - loss: 0.5110\n",
      "Epoch 22/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8424 - loss: 0.5135\n",
      "Epoch 23/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8524 - loss: 0.4984\n",
      "Epoch 24/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8530 - loss: 0.4846\n",
      "Epoch 25/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8551 - loss: 0.4810\n",
      "Epoch 26/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8573 - loss: 0.4713\n",
      "Epoch 27/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8543 - loss: 0.4777\n",
      "Epoch 28/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8593 - loss: 0.4641\n",
      "Epoch 29/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8577 - loss: 0.4817\n",
      "Epoch 30/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8649 - loss: 0.4479\n",
      "Epoch 31/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8633 - loss: 0.4474\n",
      "Epoch 32/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8585 - loss: 0.4513\n",
      "Epoch 33/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8679 - loss: 0.4296\n",
      "Epoch 34/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8645 - loss: 0.4409\n",
      "Epoch 35/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8676 - loss: 0.4404\n",
      "Epoch 36/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8710 - loss: 0.4378\n",
      "Epoch 37/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8708 - loss: 0.4188\n",
      "Epoch 38/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8748 - loss: 0.4100\n",
      "Epoch 39/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8702 - loss: 0.4229\n",
      "Epoch 40/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8707 - loss: 0.4203\n",
      "Epoch 41/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8715 - loss: 0.4121\n",
      "Epoch 42/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8798 - loss: 0.3970\n",
      "Epoch 43/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8709 - loss: 0.4137\n",
      "Epoch 44/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8816 - loss: 0.3922\n",
      "Epoch 45/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8745 - loss: 0.4028\n",
      "Epoch 46/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8762 - loss: 0.4084\n",
      "Epoch 47/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8765 - loss: 0.4023\n",
      "Epoch 48/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8796 - loss: 0.3825\n",
      "Epoch 49/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8833 - loss: 0.3828\n",
      "Epoch 50/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8821 - loss: 0.3884\n",
      "Epoch 51/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8776 - loss: 0.4060\n",
      "Epoch 52/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8860 - loss: 0.3745\n",
      "Epoch 53/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8787 - loss: 0.3880\n",
      "Epoch 54/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8811 - loss: 0.3735\n",
      "Epoch 55/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8827 - loss: 0.3814\n",
      "Epoch 56/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8848 - loss: 0.3663\n",
      "Epoch 57/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8820 - loss: 0.3681\n",
      "Epoch 58/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8833 - loss: 0.3741\n",
      "Epoch 59/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8829 - loss: 0.3750\n",
      "Epoch 60/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8892 - loss: 0.3551\n",
      "Epoch 61/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8877 - loss: 0.3691\n",
      "Epoch 62/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8854 - loss: 0.3642\n",
      "Epoch 63/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8884 - loss: 0.3567\n",
      "Epoch 64/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8906 - loss: 0.3519\n",
      "Epoch 65/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8870 - loss: 0.3608\n",
      "Epoch 66/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8896 - loss: 0.3593\n",
      "Epoch 67/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8798 - loss: 0.3687\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8878 - loss: 0.3560\n",
      "Epoch 69/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8858 - loss: 0.3664\n",
      "Epoch 70/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8880 - loss: 0.3559\n",
      "Epoch 71/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8892 - loss: 0.3594\n",
      "Epoch 72/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8916 - loss: 0.3457\n",
      "Epoch 73/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8891 - loss: 0.3421\n",
      "Epoch 74/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8884 - loss: 0.3487\n",
      "Epoch 75/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8885 - loss: 0.3507\n",
      "Epoch 76/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8866 - loss: 0.3601\n",
      "Epoch 77/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8876 - loss: 0.3459\n",
      "Epoch 78/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8888 - loss: 0.3526\n",
      "Epoch 79/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8960 - loss: 0.3462\n",
      "Epoch 80/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8901 - loss: 0.3388\n",
      "Epoch 81/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8859 - loss: 0.3538\n",
      "Epoch 82/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8919 - loss: 0.3379\n",
      "Epoch 83/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8912 - loss: 0.3436\n",
      "Epoch 84/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8976 - loss: 0.3274\n",
      "Epoch 85/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8939 - loss: 0.3364\n",
      "Epoch 86/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8974 - loss: 0.3246\n",
      "Epoch 87/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8938 - loss: 0.3286\n",
      "Epoch 88/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8894 - loss: 0.3424\n",
      "Epoch 89/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8925 - loss: 0.3381\n",
      "Epoch 90/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8999 - loss: 0.3227\n",
      "Epoch 91/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8960 - loss: 0.3287\n",
      "Epoch 92/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8944 - loss: 0.3291\n",
      "Epoch 93/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8998 - loss: 0.3249\n",
      "Epoch 94/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8938 - loss: 0.3316\n",
      "Epoch 95/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8987 - loss: 0.3216\n",
      "Epoch 96/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8941 - loss: 0.3294\n",
      "Epoch 97/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8981 - loss: 0.3269\n",
      "Epoch 98/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8947 - loss: 0.3346\n",
      "Epoch 99/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8989 - loss: 0.3244\n",
      "Epoch 100/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8997 - loss: 0.3218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x14651f8ce10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crating a Basic Initial model\n",
    "ann = Sequential()\n",
    "\n",
    "# adding input layer \n",
    "ann.add(Dense(units=20, activation='relu', input_shape=(16,)))\n",
    "\n",
    "# adding Hiddenlayer\n",
    "ann.add(Dense(units = 15, activation = 'relu'))\n",
    "\n",
    "# Adding output layer\n",
    "ann.add(Dense(units = 26, activation = 'softmax'))\n",
    "\n",
    "# creating connecction between layers\n",
    "ann.compile(optimizer= 'adam', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the data\n",
    "ann.fit(xtrain, ytrain, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "608c5f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Getting predictions from designed neural network\n",
    "ypred = ann.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88992644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ...,  True, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [ True, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False,  True, False],\n",
       "       [False, False, False, ..., False,  True, False]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting predictions into 0's and 1's\n",
    "ypred = ypred > 0.5\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "903cab76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python already treates False ad 0 and True as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17dc16fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       149\n",
      "           1       0.89      0.85      0.87       153\n",
      "           2       0.91      0.84      0.87       137\n",
      "           3       0.89      0.80      0.84       156\n",
      "           4       0.92      0.86      0.89       141\n",
      "           5       0.89      0.81      0.85       140\n",
      "           6       0.95      0.80      0.87       160\n",
      "           7       0.87      0.72      0.79       144\n",
      "           8       0.94      0.86      0.90       146\n",
      "           9       0.96      0.89      0.92       149\n",
      "          10       0.89      0.78      0.83       130\n",
      "          11       0.94      0.85      0.89       155\n",
      "          12       0.91      0.96      0.93       168\n",
      "          13       0.92      0.87      0.89       151\n",
      "          14       0.89      0.87      0.88       145\n",
      "          15       0.94      0.85      0.89       173\n",
      "          16       0.95      0.89      0.92       166\n",
      "          17       0.89      0.79      0.84       160\n",
      "          18       0.92      0.89      0.90       171\n",
      "          19       0.93      0.90      0.91       163\n",
      "          20       0.94      0.90      0.92       183\n",
      "          21       0.97      0.87      0.92       158\n",
      "          22       0.95      0.93      0.94       148\n",
      "          23       0.92      0.92      0.92       154\n",
      "          24       0.91      0.87      0.89       168\n",
      "          25       0.92      0.94      0.93       132\n",
      "\n",
      "   micro avg       0.92      0.86      0.89      4000\n",
      "   macro avg       0.92      0.86      0.89      4000\n",
      "weighted avg       0.92      0.86      0.89      4000\n",
      " samples avg       0.86      0.86      0.86      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking for classification report\n",
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d33cdbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8985 - loss: 0.3196\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8825 - loss: 0.3820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.31565040349960327, 0.9006249904632568],\n",
       " [0.37804585695266724, 0.8865000009536743])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.evaluate(xtrain, ytrain), ann.evaluate(xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "846124b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performed good model. We have very good accuracies before hyperparameter tunning.\n",
    "# The model developed is a Generalized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce623768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Hyperparameter tunning to check models performance on different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "202ed407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to create a model\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Adding layers\n",
    "    for i in range(hp.Int('num_layers', 2, 50)): # defining no. of hidden layers\n",
    "        model.add(Dense(units = hp.Int('units_' + str(i),\n",
    "                                      min_value = 32,\n",
    "                                      max_value = 512,\n",
    "                                      step = 32),\n",
    "                       activation = 'relu')) # defining no. o neurons and activation function \n",
    "    \n",
    "    # Adding Output layer\n",
    "    model.add(Dense(units = 26, activation = 'softmax'))\n",
    "    \n",
    "    # Creating connections in layers\n",
    "    optim = hp.Choice('optimizer', values = ['SGD', 'Adam', 'Adadelta', 'RMSprop'])\n",
    "    \n",
    "    model.compile(optimizer = optim, \n",
    "                  loss = 'categorical_crossentropy', \n",
    "                  metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d91b4e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting data for tunning\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective = 'val_accuracy',\n",
    "    max_trials = 5,\n",
    "    directory = 'Assignment_Test_Reports',\n",
    "    project_name = 'ANN_Assignment'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77ec3708",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 40s]\n",
      "val_accuracy: 0.4814999997615814\n",
      "\n",
      "Best val_accuracy So Far: 0.9265000224113464\n",
      "Total elapsed time: 00h 02m 23s\n"
     ]
    }
   ],
   "source": [
    "# fitting training data \n",
    "tuner.search(xtrain, ytrain, epochs = 5, validation_data = (xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bff8203f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_layers': 4,\n",
       " 'units_0': 320,\n",
       " 'units_1': 96,\n",
       " 'optimizer': 'Adam',\n",
       " 'units_2': 64,\n",
       " 'units_3': 64,\n",
       " 'units_4': 128,\n",
       " 'units_5': 160,\n",
       " 'units_6': 320,\n",
       " 'units_7': 128,\n",
       " 'units_8': 256}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for best idel parameters to create Artificial Neural Network\n",
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02b9a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best hyperparametrs to make an ANN model is -\n",
    "# 1. No. of Hidden layers should be 4.\n",
    "# 2. 1st hidden layer should have 320 units (neurons)\n",
    "# 3. 2nd hidden layer should have 96 units (neurons)\n",
    "# 4. best optimizer is \"Adam\" optimizer.\n",
    "# 5. 3rd hidden layer should have 64 units and \n",
    "# 6. 4th layer should have 64 neurons.\n",
    "\n",
    "# here optimal no. of layers are 4 so first 4 units given are iedal to madke a good model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5421177d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9408 - loss: 0.1841 - val_accuracy: 0.9265 - val_loss: 0.2306\n",
      "Epoch 2/3\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9433 - loss: 0.1750 - val_accuracy: 0.9405 - val_loss: 0.1814\n",
      "Epoch 3/3\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.1362 - val_accuracy: 0.9352 - val_loss: 0.1965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1466626d6d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a final ANN model using selected hyperparameters\n",
    "final_model = tuner.get_best_models(num_models=1)[0]\n",
    "final_model.fit(xtrain, ytrain, epochs = 3, validation_data = (xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c764882c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9538 - loss: 0.1347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13555052876472473, 0.9541875123977661]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final model evaluation\n",
    "final_model.evaluate(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d8c59ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9353 - loss: 0.2060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.19653095304965973, 0.9352499842643738]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.evaluate(xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a8ced7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here training accuracy = 95% and testing accuracy = 93%\n",
    "# The model developed is generalized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7508fc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.16029136e-04, 1.33128397e-05, 4.48448054e-06, ...,\n",
       "        7.35920221e-02, 2.50898534e-03, 2.70217508e-01],\n",
       "       [1.58025557e-03, 2.07849189e-05, 2.61940499e-04, ...,\n",
       "        2.70850098e-08, 3.90285686e-06, 1.27324871e-08],\n",
       "       [1.00000000e+00, 1.90650986e-17, 1.38621577e-20, ...,\n",
       "        2.25752102e-13, 1.88150060e-13, 2.16192841e-10],\n",
       "       ...,\n",
       "       [6.23299989e-09, 5.63282147e-12, 1.11679088e-09, ...,\n",
       "        6.46831492e-13, 1.16920820e-10, 2.08439446e-10],\n",
       "       [5.08537190e-03, 4.22566759e-10, 2.65924829e-08, ...,\n",
       "        1.11722125e-08, 9.81213152e-01, 1.27517628e-02],\n",
       "       [4.48528503e-08, 1.54101379e-16, 3.57469826e-12, ...,\n",
       "        3.77801861e-08, 9.99983907e-01, 7.44951212e-09]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = final_model.predict(xtest)\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "423a6b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = ypred > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aec58bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       149\n",
      "           1       0.96      0.85      0.90       153\n",
      "           2       0.94      0.85      0.89       137\n",
      "           3       0.97      0.94      0.96       156\n",
      "           4       0.95      0.86      0.90       141\n",
      "           5       0.93      0.92      0.92       140\n",
      "           6       0.73      0.97      0.83       160\n",
      "           7       0.97      0.74      0.84       144\n",
      "           8       0.92      0.96      0.94       146\n",
      "           9       0.97      0.95      0.96       149\n",
      "          10       0.94      0.93      0.93       130\n",
      "          11       0.98      0.95      0.97       155\n",
      "          12       0.99      0.98      0.98       168\n",
      "          13       0.96      0.94      0.95       151\n",
      "          14       0.89      0.99      0.94       145\n",
      "          15       1.00      0.91      0.95       173\n",
      "          16       1.00      0.79      0.88       166\n",
      "          17       0.92      0.89      0.91       160\n",
      "          18       0.93      0.98      0.96       171\n",
      "          19       0.99      0.88      0.93       163\n",
      "          20       0.94      0.96      0.95       183\n",
      "          21       0.95      0.95      0.95       158\n",
      "          22       0.99      0.96      0.97       148\n",
      "          23       0.99      0.90      0.94       154\n",
      "          24       0.98      0.97      0.98       168\n",
      "          25       0.96      0.98      0.97       132\n",
      "\n",
      "   micro avg       0.95      0.92      0.94      4000\n",
      "   macro avg       0.95      0.92      0.93      4000\n",
      "weighted avg       0.95      0.92      0.93      4000\n",
      " samples avg       0.92      0.92      0.92      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00ec2be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before hyperparameter tunning - \n",
    "# Training accuracy was 89% and testing accuracy was 88%.\n",
    "# after hyperparameter tunning we increased it by almost 7% - 8%.\n",
    "\n",
    "# Just by selecting only optimal no. of layers, neurons and ideal optimizer can helped to achieve good accuracy of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2c2997",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
